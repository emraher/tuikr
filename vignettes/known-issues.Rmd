---
title: "Known Issues and Limitations"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Known Issues and Limitations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

## Introduction

Known issues and workarounds for `tuikr`.

## TUIK Website Structure Changes

### The Challenge

Web scraping breaks when TUIK updates website structure.
```{r website_change}
# This may fail if TUIK has restructured their database pages
databases <- statistical_databases("110")
#> Error: Could not parse database information
```

### Workarounds

Check for updates, report issues on [GitHub](https://github.com/emraher/tuikr/issues), or use geographic functions (more stable JSON API).

## Messy Excel Files

### The Problem

TUIK Excel files have inconsistent formatting: multiple headers, mixed languages, source notes in data area, merged cells.

### Example of a Messy File

```{r messy_example}
library(readxl)
library(tuikr)

# Download a file
tables <- statistical_tables("110")
download.file(tables$datafile_url[1], destfile = "/tmp/data.xls", mode = "wb")

# Read without cleaning
raw_data <- read_xls("/tmp/data.xls")
print(raw_data)

#> # A tibble: 17 × 4
#>   `Hükümlü ve tutuklu sayısı, 2011-2020` ...2       ...3      ...4
#>   <chr>                                   <chr>      <chr>     <chr>
#> 1 Prison population, 2011-2020            <NA>       <NA>      <NA>
#> 2 Yıllar\nYears                           Toplam\... Erkek\... Kadın\...
#> 3 <NA>                                    <NA>       <NA>      <NA>
#> 4 2011                                    128253     123790    4603
#> ... (data rows)
#> 14 Kaynak: Ceza İnfaz Kurumu İstatistikleri, 2011-2020  <NA>  <NA>  <NA>
#> 15 Source: Prison Statistics, 2011-2020    <NA>       <NA>      <NA>
```

### Cleaning Strategies

```{r skip_rows}
# Skip the first few rows
clean_data <- read_xls("/tmp/data.xls", skip = 3)
```

```{r limit_rows}
clean_data <- read_xls("/tmp/data.xls", skip = 3, n_max = 10)
```

```{r remove_na}
library(tidyverse)
clean_data <- read_xls("/tmp/data.xls", skip = 2) |>
  filter(!is.na(...1)) |>
  filter(!str_detect(...1, "Kaynak|Source"))
```

```{r clean_names}
library(janitor)
clean_data <- read_xls("/tmp/data.xls", skip = 3) |>
  clean_names() |>
  rename(year = x1, total = x2)
```

Inspect files manually before automating:

```{r manual_inspect}
# View the raw file
View(read_xls("/tmp/data.xls"))

# Check dimensions
dim(read_xls("/tmp/data.xls"))

# Inspect specific rows
read_xls("/tmp/data.xls") |> slice(1:5)
read_xls("/tmp/data.xls") |> slice((n()-5):n())
```

## Network Dependencies

### Online-Only Functions

All functions require internet connectivity.

### Handling Connection Failures

```{r connection_handling}
library(tuikr)

# Use tryCatch for robust code
safely_get_themes <- function() {
  tryCatch(
    {
      statistical_themes()
    },
    error = function(e) {
      message("Could not connect to TUIK portal")
      message("Error: ", e$message)
      return(NULL)
    }
  )
}

themes <- safely_get_themes()

if (is.null(themes)) {
  stop("Cannot proceed without theme data")
}
```


## API Limitations

### Rate Limiting

```{r rate_limit}
# Add delays between requests
theme_ids <- c("110", "108", "109")
all_tables <- map_df(theme_ids, function(id) {
  Sys.sleep(1)  # Wait 1 second between requests
  statistical_tables(id)
})
```

### Data Availability by Level

Not all variables are available at all NUTS levels. The `geo_data()` function will error if you request an unavailable level:

```{r level_check}
# Check available levels before downloading
vars <- geo_data()

var_info <- vars %>%
  filter(var_num == "TFE-GK105747-O23001")

# View available levels
var_info$var_levels[[1]]  # e.g., c(2, 3) - only NUTS-2 and NUTS-3

# This will fail
geo_data(
  variable_level = 4,  # Not available!
  variable_no = "TFE-GK105747-O23001",
  variable_source = "medas",
  variable_period = "yillik",
  variable_recnum = 5
)
#> Error: This data is not available at this NUTS level (level = 4)!!!
```

Check `var_levels` before downloading:

```{r check_levels}
download_if_available <- function(var_no, level, ...) {
  vars <- geo_data()
  available_levels <- vars |>
    filter(var_num == var_no) |>
    pull(var_levels) |>
    pluck(1)

  if (level %in% available_levels) {
    geo_data(variable_level = level, variable_no = var_no, ...)
  } else {
    message(sprintf("Level %d not available for %s", level, var_no))
    message(sprintf("Available levels: %s", paste(available_levels, collapse = ", ")))
    return(NULL)
  }
}
```


## Locale and Date Parsing

### Turkish Date Formats

```{r locale}
statistical_tables("110")
```

Check system locale if encountering date parsing errors:

```{r check_locale}
Sys.getlocale("LC_TIME")

# Set Turkish locale (Unix/macOS)
Sys.setlocale("LC_TIME", "tr_TR")

# Set Turkish locale (Windows)
Sys.setlocale("LC_TIME", "Turkish_Turkey.utf8")
```

### Geographic Data Dates

```{r parse_dates}
# Annual: "2019" (4 digits), Monthly: "201901" (6 digits)
data <- geo_data(3, "SNM-GK160951-O33303", "medas", "yillik", 5) |>
  mutate(
    year = as.integer(substr(date, 1, 4)),
    month = if_else(nchar(date) == 6, as.integer(substr(date, 5, 6)), NA_integer_)
  )
```

## GitHub Issue #2

[Issue #2](https://github.com/emraher/tuikr/issues/2) tracks connection problems (timeouts, SSL errors, proxy failures).

## V8 Dependency (Historical)

V8 is now optional (in `Suggests`). Not needed for current functionality:

```{r v8_optional}
geo_map(3)
geo_data()
```

## Character Encoding

```{r encoding}
Sys.getlocale("LC_CTYPE")
Sys.setlocale("LC_CTYPE", "en_US.UTF-8")  # Unix/macOS
Sys.setlocale("LC_CTYPE", "Turkish_Turkey.utf8")  # Windows
```

## Performance Considerations

### Large Downloads

Cache results for reuse:

```{r cache}
cache_file <- "data/district_population.rds"

if (file.exists(cache_file)) {
  district_data <- readRDS(cache_file)
} else {
  district_data <- geo_data(4, "ADNKS-GK137473-O29001", "medas", "yillik", 5)
  saveRDS(district_data, cache_file)
}
```

### Map Files

```{r map_size}
lau1 <- geo_map(4)
object.size(lau1) |> format(units = "MB")

library(sf)
lau1_simple <- st_simplify(lau1, dTolerance = 0.01)
object.size(lau1_simple) |> format(units = "MB")
```

## Reporting Issues

Report issues at [github.com/emraher/tuikr/issues](https://github.com/emraher/tuikr/issues) with function call, error message, and `sessionInfo()`.

## Summary

| Issue | Severity | Workaround |
|-------|----------|------------|
| Website structure changes | High | Update package, report issues |
| Messy Excel files | Medium | Manual cleaning pipelines |
| Network dependency | Medium | Error handling, offline tests |
| Level availability | Low | Check metadata first |
| Rate limiting | Low | Add delays between requests |
| Turkish locales | Low | Set system locale |
| V8 dependency | Low (historical) | Now optional, not needed |
